import os
import torch
import lpips
import numpy as np
import argparse
from PIL import Image
from tqdm import tqdm
from torchvision import transforms
from skimage.metrics import structural_similarity as ssim
from torchmetrics.image.fid import FrechetInceptionDistance
import warnings

# Táº¯t cáº£nh bÃ¡o SSIM (thÆ°á»ng xáº£y ra khi so sÃ¡nh tensor)
warnings.filterwarnings("ignore", category=UserWarning)


# --- Utility functions ---
def load_image(path):
    """
    Táº£i áº£nh, chuyá»ƒn sang tensor vÃ  chuáº©n hÃ³a vá» dáº£i [0, 1]
    """
    try:
        img = Image.open(path).convert("RGB")
        transform = transforms.Compose([
            transforms.ToTensor()
        ])
        return transform(img).unsqueeze(0) # [1, C, H, W], dáº£i [0, 1]
    except FileNotFoundError:
        return None
    except Exception as e:
        print(f"Lá»—i khi táº£i áº£nh {path}: {e}")
        return None


def l1_loss(img1, img2):
    """TÃ­nh L1 Loss giá»¯a hai tensor [0, 1]"""
    return torch.mean(torch.abs(img1 - img2)).item()


def ssim_score(img1, img2):
    """
    TÃ­nh Structural Similarity Index (SSIM)
    YÃªu cáº§u tensor Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn sang CPU vÃ  dáº£i [0, 1]
    """
    # SSIM cáº§n tensor á»Ÿ dáº¡ng numpy (H, W, C) hoáº·c (C, H, W)
    # Ta chuyá»ƒn tá»« (1, C, H, W) -> (H, W, C) numpy
    img1_np = img1.squeeze().permute(1, 2, 0).numpy()
    img2_np = img2.squeeze().permute(1, 2, 0).numpy()
    
    # Sá»­ dá»¥ng channel_axis=2 cho Ä‘á»‹nh dáº¡ng (H, W, C) vÃ  data_range=1.0 cho áº£nh [0, 1]
    return ssim(img1_np, img2_np, channel_axis=2, data_range=1.0)


# --- Main evaluation ---
def evaluate_folder(root_folder_path, output_path=None, device='cuda' if torch.cuda.is_available() else 'cpu'):
    
    # 1. XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n thÆ° má»¥c con
    gen_folder = os.path.join(root_folder_path, "generated_images")
    gt_folder = os.path.join(root_folder_path, "gt_images")

    if not os.path.isdir(gen_folder) or not os.path.isdir(gt_folder):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c 'generated_images' hoáº·c 'gt_images' trong {root_folder_path}")
        print("Vui lÃ²ng Ä‘áº£m báº£o cáº¥u trÃºc thÆ° má»¥c lÃ : root_folder_path/generated_images vÃ  root_folder_path/gt_images")
        return

    # 2. Láº¥y danh sÃ¡ch áº£nh sinh ra
    generated_files = os.listdir(gen_folder)
    
    # Lá»c chá»‰ láº¥y cÃ¡c file .png hoáº·c .jpg
    image_extensions = ('.png', '.jpg', '.jpeg')
    generated_files = [f for f in generated_files if f.lower().endswith(image_extensions)]
    
    print(f"ğŸ“Š TÃ¬m tháº¥y {len(generated_files)} áº£nh sinh ra Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.")

    # 3. Setup models
    try:
        lpips_model = lpips.LPIPS(net='vgg').to(device)
    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi táº¡o LPIPS: {e}. Vui lÃ²ng Ä‘áº£m báº£o Ä‘Ã£ cÃ i Ä‘áº·t lpips (pip install lpips) vÃ  torchvision.")
        return
        
    fid_metric = FrechetInceptionDistance(feature=2048, normalize=True).to(device) # normalize=True cho tensor [0, 1]
    
    results = []
    gen_fid_updates = []
    gt_fid_updates = []
    
    # Biáº¿n Ä‘áº¿m Ä‘á»ƒ in ra 3 vÃ­ dá»¥ Ä‘áº§u tiÃªn
    example_count = 0
    max_examples = 3

    # 4. Duyá»‡t vÃ  Ä‘Ã¡nh giÃ¡ tá»«ng cáº·p áº£nh
    for gen_file in tqdm(generated_files, desc="ğŸ”„ Äang Ä‘Ã¡nh giÃ¡"):
        # TÃªn file sinh ra: Font_Glyph_gen.png
        # TÃªn file GT tÆ°Æ¡ng á»©ng: Font_Glyph_gt.png
        
        # Táº¡o tÃªn file GT dá»±a trÃªn tÃªn file Generated
        # Bá» Ä‘uÃ´i file (.png, .jpg) trÆ°á»›c khi tÃ¬m háº­u tá»‘
        base_filename = os.path.splitext(gen_file)[0]
        base_name_without_suffix = base_filename.rsplit('_', 1)[0] # Bá» _gen
        
        gt_file_base = f"{base_name_without_suffix}_gt"

        # Kiá»ƒm tra cáº£ 2 Ä‘á»‹nh dáº¡ng file GT (.png vÃ  .jpg)
        gt_path = os.path.join(gt_folder, f"{gt_file_base}.png")
        if not os.path.exists(gt_path):
            gt_path = os.path.join(gt_folder, f"{gt_file_base}.jpg")
            
            if not os.path.exists(gt_path):
                print(f"âš ï¸ Missing GT file cho {gen_file}. ÄÃ£ bá» qua.")
                continue

        gen_path = os.path.join(gen_folder, gen_file)
        
        # --- In ra vÃ­ dá»¥ Ä‘á»ƒ kiá»ƒm tra ---
        if example_count < max_examples:
            print(f"\n[VÃ Dá»¤ {example_count + 1}]")
            print(f"  > Generated: {gen_path}")
            print(f"  > Ground Truth: {gt_path}")
            example_count += 1
        # -------------------------------


        # Táº£i áº£nh (áº£nh Ä‘Ã£ á»Ÿ dáº£i [0, 1])
        gen_img = load_image(gen_path)
        gt_img = load_image(gt_path)

        if gen_img is None or gt_img is None:
            continue
            
        gen_img = gen_img.to(device)
        gt_img = gt_img.to(device)

        # Kiá»ƒm tra kÃ­ch thÆ°á»›c tensor trÆ°á»›c khi tÃ­nh toÃ¡n
        if gen_img.shape != gt_img.shape:
             print(f"âŒ Bá» qua cáº·p {gen_file} vÃ  {os.path.basename(gt_path)}: KÃ­ch thÆ°á»›c tensor khÃ¡c nhau ({gen_img.shape} vs {gt_img.shape})")
             continue

        # --- Per-image metrics ---
        l1_val = l1_loss(gen_img, gt_img)
        ssim_val = ssim_score(gen_img.cpu(), gt_img.cpu())
        
        # LPIPS yÃªu cáº§u áº£nh Ä‘Æ°á»£c chuáº©n hÃ³a vá» [-1, 1], nhÆ°ng lpips.LPIPS(net='vgg') 
        # thÆ°á»ng xá»­ lÃ½ chuáº©n hÃ³a ná»™i bá»™ tá»« [0, 1] sang [-1, 1] khi dÃ¹ng VGG/AlexNet.
        # Náº¿u gáº·p lá»—i, ta cÃ³ thá»ƒ pháº£i chuáº©n hÃ³a thá»§ cÃ´ng.
        try:
            lpips_val = lpips_model(gen_img, gt_img).item()
        except RuntimeError:
            # Fallback: Chuáº©n hÃ³a thá»§ cÃ´ng cho LPIPS (chuyá»ƒn [0, 1] -> [-1, 1])
            gen_lpips = gen_img * 2 - 1
            gt_lpips = gt_img * 2 - 1
            lpips_val = lpips_model(gen_lpips, gt_lpips).item()


        results.append((base_name_without_suffix, l1_val, ssim_val, lpips_val))
        
        # --- Store for FID (global) ---
        # FID metric cáº§n input lÃ  torch.uint8 (0-255)
        # Chuyá»ƒn tensor [0, 1] sang tensor [0, 255] (uint8)
        gen_fid_updates.append((gen_img * 255).byte())
        gt_fid_updates.append((gt_img * 255).byte())

    # 5. Compute FID (global)
    if not gen_fid_updates:
        print("KhÃ´ng cÃ³ cáº·p áº£nh há»£p lá»‡ Ä‘á»ƒ tÃ­nh toÃ¡n. Káº¿t thÃºc.")
        return
        
    print(f"\nGen: {len(gen_fid_updates)} áº£nh | GT: {len(gt_fid_updates)} áº£nh")

    # Cáº­p nháº­t metric FID
    for img in gen_fid_updates:
        fid_metric.update(img, real=False)
    for img in gt_fid_updates:
        fid_metric.update(img, real=True)

    try:
        fid_val = fid_metric.compute().item()
    except Exception as e:
        print(f"âŒ Lá»—i khi tÃ­nh FID: {e}. Äáº£m báº£o sá»‘ lÆ°á»£ng áº£nh Ä‘á»§ (>1) vÃ  kÃ­ch thÆ°á»›c lÃ  299x299 cho InceptionV3.")
        fid_val = float('nan')
        

    # 6. Save results
    if output_path is None:
        output_path = os.path.join(root_folder_path, "evaluation_results.txt")

    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    avg_l1 = np.mean([r[1] for r in results])
    avg_ssim = np.mean([r[2] for r in results])
    avg_lpips = np.mean([r[3] for r in results])

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("--- TÃ“M Táº®T Káº¾T QUáº¢ ÄÃNH GIÃ ---\n")
        f.write(f"Tá»•ng sá»‘ cáº·p áº£nh há»£p lá»‡: {len(results)}\n\n")
        f.write(f"Average L1: {avg_l1:.6f}\n")
        f.write(f"Average SSIM: {avg_ssim:.6f}\n")
        f.write(f"Average LPIPS: {avg_lpips:.6f}\n")
        f.write(f"FID (global): {fid_val:.6f}\n\n")
        
        f.write("--- Káº¾T QUáº¢ CHI TIáº¾T THEO Tá»ªNG Cáº¶P áº¢NH ---\n")
        f.write("Filename\tL1\tSSIM\tLPIPS\n")
        for name, l1_val, ssim_val, lpips_val in results:
            f.write(f"{name}\t{l1_val:.6f}\t{ssim_val:.6f}\t{lpips_val:.6f}\n")


    print(f"\nâœ… Done! Results saved to {output_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Evaluate generated vs GT images in a folder.")
    parser.add_argument("folder", type=str, help="Path to the ROOT folder containing 'generated_images' and 'gt_images' subfolders (e.g., ./results/unknown_content)")
    parser.add_argument("--output", type=str, default=None,
                        help="Path to save evaluation txt (default: folder/evaluation_results.txt)")
    args = parser.parse_args()

    evaluate_folder(args.folder, args.output)