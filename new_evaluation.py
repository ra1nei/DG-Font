import os
import torch
import lpips
import numpy as np
import argparse
from PIL import Image
from tqdm import tqdm
from torchvision import transforms
from skimage.metrics import structural_similarity as ssim
from torchmetrics.image.fid import FrechetInceptionDistance
import warnings

# T·∫Øt c·∫£nh b√°o SSIM (th∆∞·ªùng x·∫£y ra khi so s√°nh tensor)
warnings.filterwarnings("ignore", category=UserWarning)


# --- Utility functions ---
def load_image(path):
    """
    T·∫£i ·∫£nh, chuy·ªÉn sang tensor v√† chu·∫©n h√≥a v·ªÅ d·∫£i [0, 1]
    """
    try:
        img = Image.open(path).convert("RGB")
        transform = transforms.Compose([
            transforms.ToTensor()
        ])
        return transform(img).unsqueeze(0) # [1, C, H, W], d·∫£i [0, 1]
    except FileNotFoundError:
        return None
    except Exception as e:
        print(f"L·ªói khi t·∫£i ·∫£nh {path}: {e}")
        return None


def l1_loss(img1, img2):
    """T√≠nh L1 Loss gi·ªØa hai tensor [0, 1]"""
    return torch.mean(torch.abs(img1 - img2)).item()


def ssim_score(img1, img2):
    """
    T√≠nh Structural Similarity Index (SSIM)
    Y√™u c·∫ßu tensor ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang CPU v√† d·∫£i [0, 1]
    """
    # SSIM c·∫ßn tensor ·ªü d·∫°ng numpy (H, W, C) ho·∫∑c (C, H, W)
    # Ta chuy·ªÉn t·ª´ (1, C, H, W) -> (H, W, C) numpy
    img1_np = img1.squeeze().permute(1, 2, 0).numpy()
    img2_np = img2.squeeze().permute(1, 2, 0).numpy()
    
    # S·ª≠ d·ª•ng channel_axis=2 cho ƒë·ªãnh d·∫°ng (H, W, C) v√† data_range=1.0 cho ·∫£nh [0, 1]
    return ssim(img1_np, img2_np, channel_axis=2, data_range=1.0)


# --- Main evaluation ---
def evaluate_folder(root_folder_path, output_path=None, device='cuda' if torch.cuda.is_available() else 'cpu'):
    
    # 1. X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c con
    gen_folder = os.path.join(root_folder_path, "generated_images")
    gt_folder = os.path.join(root_folder_path, "gt_images")

    if not os.path.isdir(gen_folder) or not os.path.isdir(gt_folder):
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'generated_images' ho·∫∑c 'gt_images' trong {root_folder_path}")
        print("Vui l√≤ng ƒë·∫£m b·∫£o c·∫•u tr√∫c th∆∞ m·ª•c l√†: root_folder_path/generated_images v√† root_folder_path/gt_images")
        return

    # 2. L·∫•y danh s√°ch ·∫£nh sinh ra
    generated_files = os.listdir(gen_folder)
    
    # L·ªçc ch·ªâ l·∫•y c√°c file .png ho·∫∑c .jpg
    image_extensions = ('.png', '.jpg', '.jpeg')
    generated_files = [f for f in generated_files if f.lower().endswith(image_extensions)]
    
    print(f"üìä T√¨m th·∫•y {len(generated_files)} ·∫£nh sinh ra ƒë·ªÉ ƒë√°nh gi√°.")

    # 3. Setup models
    try:
        lpips_model = lpips.LPIPS(net='vgg').to(device)
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o LPIPS: {e}. Vui l√≤ng ƒë·∫£m b·∫£o ƒë√£ c√†i ƒë·∫∑t lpips (pip install lpips) v√† torchvision.")
        return
        
    fid_metric = FrechetInceptionDistance(feature=2048, normalize=True).to(device) # normalize=True cho tensor [0, 1]
    
    results = []
    gen_fid_updates = []
    gt_fid_updates = []

    # 4. Duy·ªát v√† ƒë√°nh gi√° t·ª´ng c·∫∑p ·∫£nh
    for gen_file in tqdm(generated_files, desc="üîÑ ƒêang ƒë√°nh gi√°"):
        # T√™n file sinh ra: Font_Glyph_gen.png
        # T√™n file GT t∆∞∆°ng ·ª©ng: Font_Glyph_gt.png
        
        # T·∫°o t√™n file GT d·ª±a tr√™n t√™n file Generated
        base_name_without_suffix = gen_file.rsplit('_', 1)[0] # B·ªè _gen.png ho·∫∑c _gen.jpg
        gt_file = f"{base_name_without_suffix}_gt.png"

        gen_path = os.path.join(gen_folder, gen_file)
        gt_path = os.path.join(gt_folder, gt_file)
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p file Generated kh√¥ng c√≥ ƒëu√¥i .png
        if not os.path.exists(gt_path):
            gt_file = f"{base_name_without_suffix}_gt.jpg"
            gt_path = os.path.join(gt_folder, gt_file)
            
            if not os.path.exists(gt_path):
                # Th·ª≠ t√¨m file GT v·ªõi t√™n file Generated y h·ªát (n·∫øu c√≥ l·ªói logic t√™n file)
                # ƒê√¢y l√† fallback n·∫øu logic ƒë·∫∑t t√™n file kh√¥ng chu·∫©n
                # gt_path_fallback = os.path.join(gt_folder, gen_file.replace("_gen", "_gt"))
                # if os.path.exists(gt_path_fallback):
                #     gt_path = gt_path_fallback
                # else:
                print(f"‚ö†Ô∏è Missing GT file cho {gen_file}. ƒê√£ b·ªè qua.")
                continue

        # T·∫£i ·∫£nh (·∫£nh ƒë√£ ·ªü d·∫£i [0, 1])
        gen_img = load_image(gen_path)
        gt_img = load_image(gt_path)

        if gen_img is None or gt_img is None:
            continue
            
        gen_img = gen_img.to(device)
        gt_img = gt_img.to(device)

        # Ki·ªÉm tra k√≠ch th∆∞·ªõc tensor tr∆∞·ªõc khi t√≠nh to√°n
        if gen_img.shape != gt_img.shape:
             print(f"‚ùå B·ªè qua c·∫∑p {gen_file} v√† {gt_file}: K√≠ch th∆∞·ªõc tensor kh√°c nhau ({gen_img.shape} vs {gt_img.shape})")
             continue

        # --- Per-image metrics ---
        l1_val = l1_loss(gen_img, gt_img)
        ssim_val = ssim_score(gen_img.cpu(), gt_img.cpu())
        
        # LPIPS y√™u c·∫ßu ·∫£nh ƒë∆∞·ª£c chu·∫©n h√≥a v·ªÅ [-1, 1], nh∆∞ng lpips.LPIPS(net='vgg') 
        # th∆∞·ªùng x·ª≠ l√Ω chu·∫©n h√≥a n·ªôi b·ªô t·ª´ [0, 1] sang [-1, 1] khi d√πng VGG/AlexNet.
        # N·∫øu g·∫∑p l·ªói, ta c√≥ th·ªÉ ph·∫£i chu·∫©n h√≥a th·ªß c√¥ng.
        try:
            lpips_val = lpips_model(gen_img, gt_img).item()
        except RuntimeError:
            # Fallback: Chu·∫©n h√≥a th·ªß c√¥ng cho LPIPS (chuy·ªÉn [0, 1] -> [-1, 1])
            gen_lpips = gen_img * 2 - 1
            gt_lpips = gt_img * 2 - 1
            lpips_val = lpips_model(gen_lpips, gt_lpips).item()


        results.append((base_name_without_suffix, l1_val, ssim_val, lpips_val))
        
        # --- Store for FID (global) ---
        # FID metric c·∫ßn input l√† torch.uint8 (0-255)
        # Chuy·ªÉn tensor [0, 1] sang tensor [0, 255] (uint8)
        gen_fid_updates.append((gen_img * 255).byte())
        gt_fid_updates.append((gt_img * 255).byte())

    # 5. Compute FID (global)
    if not gen_fid_updates:
        print("Kh√¥ng c√≥ c·∫∑p ·∫£nh h·ª£p l·ªá ƒë·ªÉ t√≠nh to√°n. K·∫øt th√∫c.")
        return
        
    print(f"\nGen: {len(gen_fid_updates)} ·∫£nh | GT: {len(gt_fid_updates)} ·∫£nh")

    # C·∫≠p nh·∫≠t metric FID
    for img in gen_fid_updates:
        fid_metric.update(img, real=False)
    for img in gt_fid_updates:
        fid_metric.update(img, real=True)

    try:
        fid_val = fid_metric.compute().item()
    except Exception as e:
        print(f"‚ùå L·ªói khi t√≠nh FID: {e}. ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªß (>1) v√† k√≠ch th∆∞·ªõc l√† 299x299 cho InceptionV3.")
        fid_val = float('nan')
        

    # 6. Save results
    if output_path is None:
        output_path = os.path.join(root_folder_path, "evaluation_results.txt")

    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    avg_l1 = np.mean([r[1] for r in results])
    avg_ssim = np.mean([r[2] for r in results])
    avg_lpips = np.mean([r[3] for r in results])

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("--- T√ìM T·∫ÆT K·∫æT QU·∫¢ ƒê√ÅNH GI√Å ---\n")
        f.write(f"T·ªïng s·ªë c·∫∑p ·∫£nh h·ª£p l·ªá: {len(results)}\n\n")
        f.write(f"Average L1: {avg_l1:.6f}\n")
        f.write(f"Average SSIM: {avg_ssim:.6f}\n")
        f.write(f"Average LPIPS: {avg_lpips:.6f}\n")
        f.write(f"FID (global): {fid_val:.6f}\n\n")
        
        f.write("--- K·∫æT QU·∫¢ CHI TI·∫æT THEO T·ª™NG C·∫∂P ·∫¢NH ---\n")
        f.write("Filename\tL1\tSSIM\tLPIPS\n")
        for name, l1_val, ssim_val, lpips_val in results:
            f.write(f"{name}\t{l1_val:.6f}\t{ssim_val:.6f}\t{lpips_val:.6f}\n")


    print(f"\n‚úÖ Done! Results saved to {output_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Evaluate generated vs GT images in a folder.")
    parser.add_argument("folder", type=str, help="Path to the ROOT folder containing 'generated_images' and 'gt_images' subfolders (e.g., ./results/unknown_content)")
    parser.add_argument("--output", type=str, default=None,
                        help="Path to save evaluation txt (default: folder/evaluation_results.txt)")
    args = parser.parse_args()

    evaluate_folder(args.folder, args.output)