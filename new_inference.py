import os
import argparse
import random
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.utils as vutils
from PIL import Image
from tqdm import tqdm
from collections import OrderedDict
import numpy as np

# --- IMPORTS T·ª™ SOURCE CODE G·ªêC ---
try:
    from models.generator import Generator
    from models.guidingNet import GuidingNet
except ImportError:
    print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'models'. H√£y ƒë·∫£m b·∫£o b·∫°n ch·∫°y script n√†y t·ª´ th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n.")
    exit(1)

# ======================
# UTILS
# ======================

def load_image_tensor(path, size, device):
    """
    Load ·∫£nh, resize, v√† chu·∫©n h√≥a v·ªÅ [-1, 1] cho GAN
    """
    if not os.path.exists(path):
        return None
    
    # Transform chu·∫©n cho GAN (th∆∞·ªùng l√† mean 0.5, std 0.5 ƒë·ªÉ v·ªÅ range [-1, 1])
    tfm = transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    try:
        img = Image.open(path).convert("RGB")
        return tfm(img).unsqueeze(0).to(device) # Th√™m batch dimension [1, C, H, W]
    except Exception as e:
        print(f"L·ªói ƒë·ªçc ·∫£nh {path}: {e}")
        return None

def save_image_with_content_style(save_dir, gen_tensor, content_path, style_path, filename):
    """
    L∆∞u ·∫£nh gh√©p: [Content | Style | Generated]
    """
    os.makedirs(save_dir, exist_ok=True)
    
    # Denormalize generated tensor t·ª´ [-1, 1] v·ªÅ [0, 1] ƒë·ªÉ l∆∞u
    gen_tensor = (gen_tensor.clone().detach().cpu() * 0.5 + 0.5).clamp(0, 1)
    
    # Convert sang PIL
    gen_pil = transforms.ToPILImage()(gen_tensor.squeeze(0))
    
    # Resize c√°c ·∫£nh kh√°c v·ªÅ c√πng k√≠ch th∆∞·ªõc v·ªõi Gen
    W, H = gen_pil.size
    
    try:
        content_pil = Image.open(content_path).convert("RGB").resize((W, H))
        style_pil = Image.open(style_path).convert("RGB").resize((W, H))
        
        # T·∫°o canvas
        merged = Image.new("RGB", (W * 3, H))
        merged.paste(content_pil, (0, 0))
        merged.paste(style_pil, (W, 0))
        merged.paste(gen_pil, (W * 2, 0))
        
        save_path = os.path.join(save_dir, filename)
        merged.save(save_path)
    except Exception as e:
        print(f"L·ªói khi l∆∞u ·∫£nh gh√©p {filename}: {e}")

def load_gan_models(args, device):
    """
    Kh·ªüi t·∫°o v√† load weight cho G_EMA v√† C_EMA
    """
    print(f"üîÑ ƒêang t·∫£i m√¥ h√¨nh t·ª´: {args.checkpoint_path}")
    
    G_EMA = Generator(args.img_size, args.sty_dim, use_sn=False).to(device)
    C_EMA = GuidingNet(args.img_size, {'cont': args.sty_dim, 'disc': args.output_k}).to(device)

    if not os.path.exists(args.checkpoint_path):
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y checkpoint: {args.checkpoint_path}")

    checkpoint = torch.load(args.checkpoint_path, map_location=device)

    def clean_state_dict(state_dict):
        new_state_dict = OrderedDict()
        for k, v in state_dict.items():
            name = k[7:] if k.startswith('module.') else k
            new_state_dict[name] = v
        return new_state_dict

    # Load G_EMA
    if 'G_EMA_state_dict' in checkpoint:
        G_EMA.load_state_dict(clean_state_dict(checkpoint['G_EMA_state_dict']))
    else:
        print("‚ö†Ô∏è Warning: Kh√¥ng th·∫•y G_EMA, d√πng G th∆∞·ªùng.")
        G_EMA.load_state_dict(clean_state_dict(checkpoint['G_state_dict']))

    # Load C_EMA
    if 'C_EMA_state_dict' in checkpoint:
        C_EMA.load_state_dict(clean_state_dict(checkpoint['C_EMA_state_dict']))
    else:
        print("‚ö†Ô∏è Warning: Kh√¥ng th·∫•y C_EMA, d√πng C th∆∞·ªùng.")
        C_EMA.load_state_dict(clean_state_dict(checkpoint['C_state_dict']))

    G_EMA.eval()
    C_EMA.eval()
    
    return G_EMA, C_EMA

def collect_files(root_dir):
    """Thu th·∫≠p file ·∫£nh ƒë·ªá quy"""
    files = []
    for root, _, filenames in os.walk(root_dir):
        for filename in filenames:
            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                files.append(os.path.join(root, filename))
    return files

# ======================
# MAIN LOGIC
# ======================

def run_inference(args):
    # 1. Setup Device
    device = torch.device(f"cuda:{args.gpu}" if torch.cuda.is_available() and args.gpu != -1 else "cpu")
    print(f"‚öôÔ∏è Thi·∫øt b·ªã: {device}")

    # 2. Load Models
    try:
        G_EMA, C_EMA = load_gan_models(args, device)
    except Exception as e:
        print(f"‚ùå L·ªói load model: {e}")
        return

    # 3. Thu th·∫≠p danh s√°ch ·∫£nh Target (Chinese)
    print(f"üìÇ ƒêang qu√©t th∆∞ m·ª•c target: {args.chinese_dir}")
    chinese_images = collect_files(args.chinese_dir)
    print(f"üìä T√¨m th·∫•y {len(chinese_images)} ·∫£nh target.")

    # 4. Chu·∫©n b·ªã danh s√°ch samples (Matching logic)
    samples = []
    
    # Logic random style seed
    random.seed(42) 

    for chi_path in chinese_images:
        # C·∫•u tr√∫c: .../chinese/FontName/GlyphName.png
        font_name = os.path.basename(os.path.dirname(chi_path)) # T√™n Font
        glyph_name = os.path.splitext(os.path.basename(chi_path))[0] # T√™n ch·ªØ (vd: ‰∏Å)

        # A. X√°c ƒë·ªãnh Content Path (Source)
        # Gi·∫£ ƒë·ªãnh source n·∫±m trong args.source_dir/GlyphName.png
        # (Ho·∫∑c n·∫øu source c≈©ng chia folder th√¨ c·∫ßn s·ª≠a l·∫°i logic n√†y t√πy c·∫•u tr√∫c source c·ªßa b·∫°n)
        # Theo ƒë·ªÅ b√†i: "l·∫•y glyph c·ªßa ·∫£nh ƒë√≥ trong source l√†m ·∫£nh content" -> source_dir/glyph_name.png
        content_path = os.path.join(args.source_dir, f"{glyph_name}.png")
        
        # Fallback n·∫øu trong source n√≥ n·∫±m trong folder con (v√≠ d·ª• source/A+/glyph.png)
        if not os.path.exists(content_path):
             # Th·ª≠ t√¨m ƒë·ªá quy ho·∫∑c gi·∫£ ƒë·ªãnh m·ªôt c·∫•u tr√∫c kh√°c n·∫øu c·∫ßn. 
             # Hi·ªán t·∫°i gi·ªØ simple: source_dir/glyph.png
             pass

        # B. X√°c ƒë·ªãnh Style Path (English)
        # Style n·∫±m trong: english_dir/FontName/...
        style_dir = os.path.join(args.english_dir, font_name)
        
        if not os.path.exists(style_dir):
            continue # Kh√¥ng c√≥ folder style t∆∞∆°ng ·ª©ng font n√†y -> Skip

        # Logic ch·ªçn file Style (Random vs Fixed)
        style_file = None
        
        if args.random_style:
            # L·∫•y danh s√°ch ·∫£nh trong folder style ƒë√≥
            candidates = [f for f in os.listdir(style_dir) if f.lower().endswith(('.png', '.jpg'))]
            
            # L·ªçc theo mode n·∫øu c·∫ßn (v√≠ d·ª• ch·ªâ l·∫•y ch·ªØ hoa)
            if args.random_mode == "upper":
                # L·ªçc th√¥ s∆°: T√™n file d√†i 1 k√Ω t·ª± v√† l√† ch·ªØ hoa (A.png) ho·∫∑c A+.png
                candidates = [f for f in candidates if f[0].isupper()]
            
            if candidates:
                style_file = random.choice(candidates)
        else:
            # Fixed style (v√≠ d·ª• ch·ªçn 'A+.png' ho·∫∑c 'a.png')
            # Th·ª≠ t√¨m file ch√≠nh x√°c
            possible_names = [args.fixed_style, args.fixed_style + ".png", args.fixed_style + ".jpg"]
            for name in possible_names:
                if os.path.exists(os.path.join(style_dir, name)):
                    style_file = name
                    break
        
        if style_file:
            style_path = os.path.join(style_dir, style_file)
            
            # Ch·ªâ th√™m v√†o list n·∫øu c·∫£ Content v√† Style ƒë·ªÅu t·ªìn t·∫°i
            if os.path.exists(content_path) and os.path.exists(style_path):
                samples.append({
                    "content": content_path,
                    "style": style_path,
                    "target": chi_path,
                    "font_name": font_name,
                    "glyph_name": glyph_name
                })

    print(f"‚úÖ ƒê√£ gh√©p c·∫∑p th√†nh c√¥ng: {len(samples)} m·∫´u.")

    # 5. Ch·∫°y Inference Loop
    os.makedirs(args.save_dir, exist_ok=True)
    
    with torch.no_grad():
        for s in tqdm(samples, desc="üöÄ Running Inference", ncols=100):
            # Load Tensors
            c_img = load_image_tensor(s["content"], args.img_size, device)
            s_img = load_image_tensor(s["style"], args.img_size, device)
            
            if c_img is None or s_img is None:
                continue

            # --- GAN FORWARD PASS ---
            # 1. Extract Content
            c_code, skip1, skip2 = G_EMA.cnt_encoder(c_img)
            # 2. Extract Style
            s_code = C_EMA(s_img, sty=True)
            # 3. Decode / Generate
            fake_img, _ = G_EMA.decode(c_code, s_code, skip1, skip2)
            # ------------------------

            # Save Results
            # T√™n file: Font_Glyph_Generated.png
            safe_glyph = "".join([c if c.isalnum() else "_" for c in s["glyph_name"]]) # X·ª≠ l√Ω k√Ω t·ª± ƒë·∫∑c bi·ªát
            base_name = f"{s['font_name']}_{safe_glyph}"
            
            normalized_fake_img = (fake_img.clone().detach() * 0.5 + 0.5).clamp(0, 1)
            
            # 1. L∆∞u ·∫£nh l·∫ª (Generated)
            # D√πng normalize=False v√¨ ·∫£nh ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a th·ªß c√¥ng
            vutils.save_image(
                normalized_fake_img, 
                os.path.join(args.save_dir, f"{base_name}_gen.png"),
                normalize=False,  # B·ªè normalize=True v√† tham s·ªë range
            )

            # 2. L∆∞u ·∫£nh gh√©p (Content | Style | Gen) - H√†m n√†y ƒë√£ ƒë∆∞·ª£c s·ª≠a b√™n trong
            save_image_with_content_style(
                save_dir=os.path.join(args.save_dir, "merged_view"),
                gen_tensor=fake_img, # V·∫´n truy·ªÅn tensor [-1, 1] v√¨ h√†m save_image_with_content_style x·ª≠ l√Ω
                content_path=s["content"],
                style_path=s["style"],
                filename=f"{base_name}_merged.jpg"
            )

    print(f"\nüéâ Ho√†n t·∫•t! K·∫øt qu·∫£ l∆∞u t·∫°i: {args.save_dir}")

def parse_args():
    parser = argparse.ArgumentParser(description="Inference GAN Font Generation")
    
    # Paths
    parser.add_argument('--checkpoint_path', type=str, required=True, help='Path to .pth model')
    parser.add_argument('--source_dir', type=str, required=True, help='Folder ch·ª©a ·∫£nh Content g·ªëc (Source)')
    parser.add_argument('--chinese_dir', type=str, required=True, help='Folder ch·ª©a ·∫£nh Target (Chinese) - D√πng ƒë·ªÉ duy·ªát danh s√°ch')
    parser.add_argument('--english_dir', type=str, required=True, help='Folder ch·ª©a ·∫£nh Style (English)')
    parser.add_argument('--save_dir', type=str, default='./results', help='Folder l∆∞u k·∫øt qu·∫£')

    # Style Logic
    parser.add_argument("--random_style", action="store_true", help="Ch·ªçn style ng·∫´u nhi√™n t·ª´ folder English")
    parser.add_argument("--random_mode", type=str, default="full", choices=["full", "upper"], help="Ch·∫ø ƒë·ªô random")
    parser.add_argument("--fixed_style", type=str, default="A", help="T√™n file style c·ªë ƒë·ªãnh (VD: A, A+, a) n·∫øu kh√¥ng d√πng random")

    # Model Params
    parser.add_argument('--img_size', type=int, default=80, help='K√≠ch th∆∞·ªõc ·∫£nh model (default: 80)')
    parser.add_argument('--sty_dim', type=int, default=128, help='Style vector dimension')
    parser.add_argument('--output_k', type=int, default=400, help='S·ªë class output c·ªßa GuidingNet')
    parser.add_argument('--gpu', type=int, default=0, help='GPU ID (-1 for CPU)')

    return parser.parse_args()

if __name__ == '__main__':
    args = parse_args()
    run_inference(args)